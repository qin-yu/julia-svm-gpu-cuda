# Julia SVM Helper Functions
```julia
##############################
## by Qin Yu, Feb 2019
## using Julia 1.0.3
##############################

gaussian_kernel_matrix(ğ‘‹, Î³) =  # ğ‘‹'s rows are input tensors.
    exp.(- Î³ * pairwise(SqEuclidean(), Matrix(ğ‘‹), dims=1))
gaussian_kernel_matrix(ğ‘‹, ğ‘‹_test, Î³) =  # ğ‘‹'s rows are input tensors.
    exp.(- Î³ * pairwise(SqEuclidean(), Matrix(ğ‘‹_test), Matrix(ğ‘‹), dims=1))

function extract_each_classes(ğ‘‹_ALL, ğ’š_ALL)
    CLASSES = sort(unique(ğ’š_ALL))
    NO_OF_CLASSES = length(CLASSES)
    L = [sum(ğ’š_ALL .== class) for class in CLASSES]
    ğ‘‹_EACH_train = [ğ‘‹_ALL[:,:,ğ’š_ALL .== class] for class in CLASSES]
    ğ‘‹s = [hcat(transpose(reshape(ğ‘‹_EACH_train[i], 28*28, L[i])), ones(L[i])) for i = 1:NO_OF_CLASSES]
    ğ’šs = ones.(Int, L) .* CLASSES
    return L, ğ‘‹s, ğ’šs
end

function extract_all_test(ğ‘‹_ALL, ğ’š_ALL)
    ğ‘‹s = hcat(transpose(reshape(ğ‘‹_ALL, 28*28, :)), ones(size(ğ‘‹_ALL, 3)))
    return ğ‘‹s, ğ’š_ALL
end

function prepare_one_vs_rest(ğ‘‹_ALL, ğ’š_ALL)
    ğ‘‹ = hcat(transpose(reshape(ğ‘‹_ALL, 28*28, :)), ones(size(ğ‘‹_ALL, 3)))
    ğ’šs = [(y -> y == pos_label ? 1 : -1).(ğ’š_ALL) for pos_label = 0:9]
    return ğ‘‹, ğ’šs
end

function prepare_MNIST_data(class_pos, class_neg, Î³)
    # Load train data
    ğ‘‹_ALL_train, ğ’š_ALL_train = MNIST.traindata(Float32)

    NO_OF_NEGATIVE = sum(ğ’š_ALL_train .== class_neg)
    NO_OF_POSITIVE = sum(ğ’š_ALL_train .== class_pos)
    l = NO_OF_NEGATIVE + NO_OF_POSITIVE

    ğ‘‹_neg_train = ğ‘‹_ALL_train[:,:,ğ’š_ALL_train .== class_neg]
    ğ‘‹_pos_train = ğ‘‹_ALL_train[:,:,ğ’š_ALL_train .== class_pos]
    ğ’š_neg_train = - ones(Int, NO_OF_NEGATIVE)
    ğ’š_pos_train =   ones(Int, NO_OF_POSITIVE)

    randomisation = randperm(l)
    ğ‘‹ = hcat(transpose(reshape(cat(ğ‘‹_neg_train, ğ‘‹_pos_train; dims=3), 28*28, l)), ones(l))[randomisation,:]
    ğ’š = vcat(ğ’š_neg_train, ğ’š_pos_train)[randomisation,:]

    gaussian_kernel_matrix(ğ‘‹, Î³) = exp.(- Î³ * pairwise(SqEuclidean(), Matrix(ğ‘‹), dims=1))  # ğ‘‹'s rows are input tensors.
    K = gaussian_kernel_matrix(ğ‘‹, Î³)

    # Load test data
    ğ‘‹_ALL_test,  ğ’š_ALL_test  = MNIST.testdata(Float32)

    NO_OF_NEGATIVE_test = sum(ğ’š_ALL_test .== class_neg)
    NO_OF_POSITIVE_test = sum(ğ’š_ALL_test .== class_pos)
    l_test = NO_OF_NEGATIVE_test + NO_OF_POSITIVE_test

    ğ‘‹_neg_test = ğ‘‹_ALL_test[:,:,ğ’š_ALL_test .== class_neg]
    ğ‘‹_pos_test = ğ‘‹_ALL_test[:,:,ğ’š_ALL_test .== class_pos]
    ğ’š_neg_test = - ones(Int, NO_OF_NEGATIVE_test)
    ğ’š_pos_test =   ones(Int, NO_OF_POSITIVE_test)

    ğ‘‹_test = hcat(transpose(reshape(cat(ğ‘‹_neg_test, ğ‘‹_pos_test; dims=3), 28*28, l_test)), ones(l_test))
    ğ’š_test = vcat(ğ’š_neg_test, ğ’š_pos_test)

    gaussian_kernel_matrix(ğ‘‹, ğ‘‹_test, Î³) = exp.(- Î³ * pairwise(SqEuclidean(), Matrix(ğ‘‹_test), Matrix(ğ‘‹), dims=1))
    K_test = gaussian_kernel_matrix(ğ‘‹, ğ‘‹_test, Î³)

    return (ğ‘‹, ğ’š, K, l), (ğ‘‹_test, ğ’š_test, K_test, l_test)
end

# Only as termination criterion for the whole process.
function monitor_kkt_condition(ğœ¶, ğˆ, ğ’š; accuracy=1e-2, ğ¶::Int32=Int32(1))
    ğ‘¦ğ‘“ğ’™ = ğ’š .* ğˆ
    for (idx,Î±) in enumerate(ğœ¶)
        if Î± == 0 && ğ‘¦ğ‘“ğ’™[idx] < 1
            return false
        elseif Î± == ğ¶ && ğ‘¦ğ‘“ğ’™[idx] > 1
            return false
        elseif 0 < Î± < ğ¶ && !isapprox(ğ‘¦ğ‘“ğ’™[idx], 1; atol=accuracy)
            return false
        end
    end
    return true
end

function select_new_points(ğœ¶, ğˆ, ğ’š, ğ‘€, support_vector_idx; accuracy=1e-2, ğ¶::Int32=Int32(1))
    ğ‘¦ğ‘“ğ’™ = ğ’š .* ğˆ
    list_of_new_ids = Int[]
    list_of_new_min = Float64[]
    for (idx,Î±) in enumerate(ğœ¶)
        if (Î± == 0 && ğ‘¦ğ‘“ğ’™[idx] < 1) || (Î± == ğ¶ && ğ‘¦ğ‘“ğ’™[idx] > 1) || (0 < Î± < ğ¶ && !isapprox(ğ‘¦ğ‘“ğ’™[idx], 1; atol=accuracy))
            push!(list_of_new_ids, idx)
            push!(list_of_new_min, ğ‘¦ğ‘“ğ’™[idx])
        end
    end
    list_of_new_ids = list_of_new_ids[sortperm(list_of_new_min)]
    setdiff!(list_of_new_ids, support_vector_idx)
    return list_of_new_ids
end
```


# Julia SVM
```julia
##############################
## by Qin Yu, Apr 2019
## using Julia 1.1.0
##############################

using Revise, BenchmarkTools                           # Development
using JLD2, FileIO, MLDatasets                         # Data & IO
using LinearAlgebra, Distances, Random, Distributions  # Maths
using CUDAdrv, CUDAnative, CuArrays                    # GPU

MAX_MINI_BATCH_ID = 50

#################### Compute Adatron SGD in GPU: ####################
@inline sync_threads_and(predicate::Int32) = ccall("llvm.nvvm.barrier0.and", llvmcall, Int32, (Int32,), predicate)
@inline sync_threads_and(predicate::Bool) = ifelse(sync_threads_and(Int32(predicate)) !== Int32(0), true, false)

function kernel_soft_SGD_SVM(ğœ¶, ğˆ, K, ğ’š, l::Int32, ğ¶::Int32)
    j = (blockIdx().x-1) * blockDim().x + threadIdx().x
    can_stop = false
    Î´áµ¢ = @cuStaticSharedMem(Float32, 1)
    while !sync_threads_and(can_stop)
        last_Î±_j = ğœ¶[j]
        # Adatron:
        for i = 1:l
            if j == i  # Online
                last_Î± = ğœ¶[i]
                ğœ‡áµ¢ = 1 / K[i,i]
                Î´áµ¢[1] = ğœ‡áµ¢ * (1 - ğ’š[i] * ğˆ[i])
                ğœ¶[i] = ğœ¶[i] + Î´áµ¢[1]
                ğœ¶[i] < 0 && (ğœ¶[i] = 0; Î´áµ¢[1] = 0 - last_Î±)
                ğœ¶[i] > ğ¶ && (ğœ¶[i] = ğ¶; Î´áµ¢[1] = ğ¶ - last_Î±)
            end
            sync_threads()
            ğˆ[j] += Î´áµ¢[1] * ğ’š[i] * K[i,j]  # Parallel update
        end
        # Stopping criterion:
        can_stop = false
        isapprox(ğœ¶[j], last_Î±_j; atol=1e-4) && (can_stop = true)
    end
    return nothing
end

function optimise_working_set(ğœ¶, ğˆ, K, ğ’š; ğ¶::Int32=Int32(1))
    l = Int32(length(ğœ¶))
    cu_ğœ¶ = CuArray{Float32}(ğœ¶)
    cu_ğˆ = CuArray{Float32}(ğˆ)
    cu_K = CuArray{Float32}(K)
    cu_ğ’š = CuArray{Float32}(ğ’š)

    @cuda threads=l kernel_soft_SGD_SVM(cu_ğœ¶, cu_ğˆ, cu_K, cu_ğ’š, l, ğ¶)

    ğœ¶ = Array{Float32}(cu_ğœ¶)
    return ğœ¶
end

function optimise_working_set_CPU(ğœ¶, ğˆ, K, ğ’š; ğ¶=1)
    l = length(ğœ¶)
    while true
        last_ğœ¶ = copy(ğœ¶)
        for i = 1:l
            ğœ‡áµ¢ = 1 / K[i,i]
            Î´áµ¢ = ğœ‡áµ¢ * (1 - ğ’š[i] * ğˆ[i])
            ğœ¶[i] = ğœ¶[i] + Î´áµ¢
            ğœ¶[i] < 0 && (ğœ¶[i] = 0; Î´áµ¢ = 0 - last_ğœ¶[i])
            ğœ¶[i] > ğ¶ && (ğœ¶[i] = ğ¶; Î´áµ¢ = ğ¶ - last_ğœ¶[i])
            ğˆ .+= Î´áµ¢ * ğ’š[i] * K[i,:]
        end
        all(isapprox.(last_ğœ¶, ğœ¶; atol=1e-4)) && break
    end
    return ğœ¶
end

function stochastic_decomposition_test(ğ¶, ğ‘€, ACCURACY, l, ğ’š, K, l_test, ğ’š_test, K_test; usecpu=false)
    ğ‘€_safe = div(ğ‘€, 4) * 3
    ğ‘€_rand = ğ‘€ - ğ‘€_safe

    ğœ¶ = zeros(Float32, l)
    ğˆ = zeros(Float32, l)

    selected_new_idx = []
    support_vector_idx, alpha0_vector_idx = collect(1:ğ‘€), collect(ğ‘€+1:l)
    working_set_counter = zeros(Int32, l)

    batch_id = 0
    while !monitor_kkt_condition(ğœ¶, ğˆ, ğ’š; ğ¶=ğ¶) && batch_id < MAX_MINI_BATCH_ID
        batch_id += 1

        current_working_set_counter = working_set_counter[support_vector_idx]
        sorted_support_vector_idx = support_vector_idx[sortperm(current_working_set_counter)]

        if length(support_vector_idx) >= ğ‘€_safe
            no_of_new_idx = min(length(selected_new_idx), ğ‘€_rand)
        else
            no_of_new_idx = min(length(selected_new_idx), ğ‘€-length(support_vector_idx))
        end

        no_of_old_idx = length(support_vector_idx)
        no_of_exceeds = no_of_new_idx + no_of_old_idx - ğ‘€
        if no_of_exceeds > 0
            abandoned_support_vector_idx = sorted_support_vector_idx[end+1-no_of_exceeds:end]
            setdiff!(support_vector_idx, abandoned_support_vector_idx)
            union!(alpha0_vector_idx, abandoned_support_vector_idx)
        end
        selected_new_idx = selected_new_idx[1:no_of_new_idx]
        union!(support_vector_idx, selected_new_idx)
        setdiff!(alpha0_vector_idx, selected_new_idx)

        working_set_counter[support_vector_idx] .+= 1
        ğœ¶_subset, ğˆ_subset = ğœ¶[support_vector_idx], ğˆ[support_vector_idx]
        ğ’š_subset, K_subset = ğ’š[support_vector_idx], K[support_vector_idx,support_vector_idx]
        if usecpu
            ğœ¶[support_vector_idx] = optimise_working_set_CPU(ğœ¶_subset, ğˆ_subset, K_subset, ğ’š_subset; ğ¶=ğ¶)
        else
            ğœ¶[support_vector_idx] = optimise_working_set(ğœ¶_subset, ğˆ_subset, K_subset, ğ’š_subset; ğ¶=ğ¶)
        end

        ğˆ = K * (ğœ¶ .* ğ’š)

        for (i_index,i) in enumerate(support_vector_idx)
            if ğœ¶[i] == 0
                deleteat!(support_vector_idx, i_index)
                push!(alpha0_vector_idx, i)
            end
        end

        selected_new_idx = select_new_points(ğœ¶, ğˆ, ğ’š, ğ‘€, support_vector_idx; accuracy=ACCURACY, ğ¶=ğ¶)
    end

    ğ’šÌ‚      = sign.(ğˆ)
    ğ’šÌ‚_test = sign.(K_test * (ğœ¶ .* ğ’š))
    error_rate      = count(ğ’šÌ‚ .!= ğ’š) / l * 100
    error_rate_test = count(ğ’šÌ‚_test .!= ğ’š_test) / l_test * 100
    return ğœ¶, error_rate, error_rate_test, monitor_kkt_condition(ğœ¶, ğˆ, ğ’š; ğ¶=ğ¶)
end

function stochastic_decomposition(ğ¶, ğ‘€, ACCURACY, l, ğ’š, K; usecpu=false)
    ğ‘€_safe = div(ğ‘€, 4) * 3
    ğ‘€_rand = ğ‘€ - ğ‘€_safe

    ğœ¶ = zeros(Float32, l)
    ğˆ = zeros(Float32, l)

    selected_new_idx = []
    support_vector_idx, alpha0_vector_idx = collect(1:ğ‘€), collect(ğ‘€+1:l)
    working_set_counter = zeros(Int32, l)

    batch_id = 0
    while !monitor_kkt_condition(ğœ¶, ğˆ, ğ’š; accuracy=ACCURACY, ğ¶=ğ¶) && batch_id < MAX_MINI_BATCH_ID
        batch_id += 1

        current_working_set_counter = working_set_counter[support_vector_idx]
        sorted_support_vector_idx = support_vector_idx[sortperm(current_working_set_counter)]

        if length(support_vector_idx) >= ğ‘€_safe
            no_of_new_idx = min(length(selected_new_idx), ğ‘€_rand)
        else
            no_of_new_idx = min(length(selected_new_idx), ğ‘€-length(support_vector_idx))
        end

        no_of_old_idx = length(support_vector_idx)
        no_of_exceeds = no_of_new_idx + no_of_old_idx - ğ‘€
        if no_of_exceeds > 0
            abandoned_support_vector_idx = sorted_support_vector_idx[end+1-no_of_exceeds:end]
            setdiff!(support_vector_idx, abandoned_support_vector_idx)
            union!(alpha0_vector_idx, abandoned_support_vector_idx)
        end
        selected_new_idx = selected_new_idx[1:no_of_new_idx]
        union!(support_vector_idx, selected_new_idx)
        setdiff!(alpha0_vector_idx, selected_new_idx)

        working_set_counter[support_vector_idx] .+= 1
        ğœ¶_subset, ğˆ_subset = ğœ¶[support_vector_idx], ğˆ[support_vector_idx]
        ğ’š_subset, K_subset = ğ’š[support_vector_idx], K[support_vector_idx,support_vector_idx]
        if usecpu
            println("using CPU")
            ğœ¶[support_vector_idx] = optimise_working_set_CPU(ğœ¶_subset, ğˆ_subset, K_subset, ğ’š_subset; ğ¶=ğ¶)
        else
            ğœ¶[support_vector_idx] = optimise_working_set(ğœ¶_subset, ğˆ_subset, K_subset, ğ’š_subset; ğ¶=ğ¶)
        end
        ğˆ = K * (ğœ¶ .* ğ’š)

        for (i_index,i) in enumerate(support_vector_idx)
            if ğœ¶[i] == 0
                deleteat!(support_vector_idx, i_index)
                push!(alpha0_vector_idx, i)
            end
        end

        selected_new_idx = select_new_points(ğœ¶, ğˆ, ğ’š, ğ‘€, support_vector_idx; accuracy=ACCURACY, ğ¶=ğ¶)
    end

    ğ’šÌ‚ = sign.(ğˆ)
    error_rate = count(ğ’šÌ‚ .!= ğ’š) / l * 100
    return ğœ¶, error_rate, monitor_kkt_condition(ğœ¶, ğˆ, ğ’š; accuracy=ACCURACY, ğ¶=ğ¶)
end
```

# MNIST Training and Testing
```julia
##############################
## by Qin Yu, Apr 2019
## using Julia 1.1.0
##############################

#################### MNIST One-vs-One Multi-class ####################
function MNIST_train(L, L_test, ğ‘‹s, ğ’šs, ğ¶, ğ‘€, ACCURACY, Î³; usecpu=false)
    time_K_spent = time_GPU_spent = time_total_spent = 0
    time_total_start = time()

    randomisation_list = Array{Int32,1}[]
    ğœ¶_list = Array{Float32,1}[]
    error_list = Float64[]
    error_list_test = Float64[]
    finished_list = Bool[]
    time_ivj_list = Float64[]

    for ci = 1:10, cj = 1:10
        ci >= cj && continue
        print("$(ci-1)-vs-$(cj-1) - ")

        time_K_start = time()
        l = L[ci] + L[cj]
        randomisation = randperm(l)
        ğ’š = vcat(ones(Int32, size(ğ’šs[ci])), -ones(Int32, size(ğ’šs[cj])))[randomisation,:]
        ğ‘‹ = vcat(ğ‘‹s[ci], ğ‘‹s[cj])[randomisation,:]
        K = gaussian_kernel_matrix(ğ‘‹, Î³)
        time_K_spent += time() - time_K_start

        # l_test = L_test[ci] + L_test[cj]
        # randomisation_test = randperm(l_test)
        # ğ’š_test = vcat(ones(Int32, size(ğ’šs_test[ci])), -ones(Int32, size(ğ’šs_test[cj])))[randomisation_test,:]
        # ğ‘‹_test = vcat(ğ‘‹s_test[ci], ğ‘‹s_test[cj])[randomisation_test,:]
        # K_test = gaussian_kernel_matrix(ğ‘‹, ğ‘‹_test, Î³)

        time_GPU_start = time()
        ğœ¶, error_rate, finished = stochastic_decomposition(ğ¶, ğ‘€, ACCURACY, l, ğ’š, K; usecpu=usecpu)
        # ğœ¶, error_rate, error_rate_test, finished =
        #     stochastic_decomposition(ğ¶, ğ‘€, l, ğ’š, K, l_test, ğ’š_test, K_test)
        time_GPU_spent_this = time() - time_GPU_start
        push!(time_ivj_list, time_GPU_spent_this)
        time_GPU_spent += time_GPU_spent_this

        println("error rate = $error_rate% ; finished = $finished ; time = $time_GPU_spent_this")
        # println("error rate = $error_rate% ; test error rate = $error_rate_test% ;
        #     finished = $finished ; time = $time_GPU_spent_this")

        push!(randomisation_list, randomisation)
        push!(ğœ¶_list, ğœ¶)
        push!(error_list, error_rate)
        # push!(error_list_test, error_rate_test)
        push!(finished_list, finished)
    end

    time_total_spent = time() - time_total_start
    return ([time_K_spent, time_GPU_spent, time_total_spent],
            randomisation_list, ğœ¶_list, error_list, error_list_test, finished_list, time_ivj_list)
end

function MNIST_test_slave(ğ‘‹_ALL, ğ’š_ALL, ğ‘‹s, ğ’šs, ğœ¶_list, randomisation_list, Î³)
    i = 0
    ğ’šÌ‚_test_list = Array{Int}[]
    for ci = 1:10, cj = 1:10
        ci >= cj && continue
        print("$(ci-1)-vs-$(cj-1) - ")
        i += 1

        ğ‘‹_test, ğ’š_test = extract_all_test(ğ‘‹_ALL, ğ’š_ALL)
        K_test = gaussian_kernel_matrix(vcat(ğ‘‹s[ci], ğ‘‹s[cj])[randomisation_list[i],:], ğ‘‹_test, Î³)
        ğ’š_true = vcat(ones(Int32, size(ğ’šs[ci])), -ones(Int32, size(ğ’šs[cj])))[randomisation_list[i],:]
        ğˆ_test = K_test * (ğœ¶_list[i] .* ğ’š_true)
        ğ’šÌ‚_test = (y -> y > 0 ? ci-1 : cj-1).(ğˆ_test)

        push!(ğ’šÌ‚_test_list, ğ’šÌ‚_test)
    end
    return ğ’šÌ‚_test_list
end

function MNIST_test(ğ’š_test, ğ’šÌ‚_test_list)
    ğ’šÌ‚_test_matrix = hcat(ğ’šÌ‚_test_list...)
    ğ’šÌ‚_test = mapslices(mode, ğ’šÌ‚_test_matrix; dims=2)
    error_rate_test = count(ğ’šÌ‚_test .!= ğ’š_test) / length(ğ’š_test) * 100
    correct_rate_test = 100 - error_rate_test  # First run: 99.1%
    return ğ’šÌ‚_test, error_rate_test, correct_rate_test
end

function run(ğ¶::Int32=Int32(1),    # Penalty
              ğ‘€::Int=512,          # Max size of minibatch
              ACCURACY=1e-2,       # GPU accuracy = 0.01 * ACCURACY
              Î³=0.015;             # Gaussian kernel parameter
              usecpu=false)
    ğ‘‹_ALL, ğ’š_ALL = MNIST.traindata(Float32)
    ğ‘‹_ALL_test, ğ’š_ALL_test = MNIST.testdata(Float32)
    L, ğ‘‹s, ğ’šs = extract_each_classes(ğ‘‹_ALL, ğ’š_ALL)
    L_test, ğ‘‹s_test, ğ’šs_test = extract_each_classes(ğ‘‹_ALL_test,  ğ’š_ALL_test)

    @time time_list, randomisation_list, ğœ¶_list, error_list, error_list_test, finished_list, time_ivj_list =
        MNIST_train(L, L_test, ğ‘‹s, ğ’šs, ğ¶, ğ‘€, ACCURACY, Î³; usecpu=usecpu)
    @save "1v1.jld2" time_list, randomisation_list, ğœ¶_list, error_list, error_list_test, finished_list, time_ivj_list
    @time ğ’šÌ‚_test_list = MNIST_test_slave(ğ‘‹_ALL, ğ’š_ALL, ğ‘‹s, ğ’šs, ğœ¶_list, randomisation_list, Î³)
    @time ğ’šÌ‚_test, error_rate_test = MNIST_test(ğ’š_ALL, ğ’šÌ‚_test_list)
    println(error_rate_test)
end
```
